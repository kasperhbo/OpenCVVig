import cv2import numpy as npfrom ffpyplayer.player import MediaPlayerimport time# Ik denk dat niet gaat werken.vid_right_path = 'assets/videos/right.mp4'vid_left_path = 'assets/videos/left.mp4'x_shift = 0y_shift = 0zoom = 0resolution_width = 1920resolution_height = 1080wait_for_key_per_frame = Falseright_has_audio = Trueleft_has_audio = Falseplay_left = Trueplay_right = Falsedef stitch_images(img_left, img_right):    # image_right = self.shift_image_vertically(img_left, right_y_shift)    return np.concatenate((img_left, img_right), axis=1)def apply_video_controls(img):    # VID CONTROLS HERE    return imgdef resize_img(img):    # resize based on res width and height    dim = (resolution_width, resolution_height)    # resize image    resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)    return resizeddef show_frame_in_webpage(img):    passdef show_frame_opencv(img, audioplayer):    #video    cv2.imshow('final frame', img)    #audio    if audio_player is not None:        audio_frame, ret= audioplayer.get_frame()        if ret != 'eof' and audio_frame is not None:            # audio            img, t = audio_framedef read_next_file():    return Nonedef stop_video_stream():    # When everything done, release the video capture object    if play_left:        vid_right.release()    if play_right:        vid_left.release()    # Closes all the frames    cv2.destroyAllWindows()# open video's // Download from:# https://h2909571.stratoserver.net/Recordings/2020-03-07-14-29-01/if play_left:    vid_left = cv2.VideoCapture(vid_left_path)if play_right:    vid_right = cv2.VideoCapture(vid_right_path)audio_player = Noneif left_has_audio:    audio_player = MediaPlayer(vid_left_path)elif right_has_audio:    audio_player = MediaPlayer(vid_right_path)fps = int(vid_left.get(cv2.CAP_PROP_FPS))print('fps: ', fps)# Read until video is completedwhile 1:    # Capture frame-by-frame    if play_left:        ret_left, frame_left = vid_left.read()    if play_right:        ret_right, frame_right = vid_right.read()    final = None    if play_left is True and play_right is True:        if not ret_left or not ret_right:            stop_video_stream()        else:            stitched_frame = stitch_images(img_left=frame_left, img_right=frame_right)            # set values shift and zoom using keyboard and mouse            applied_vid_controls_frame = apply_video_controls(stitched_frame)            final = resize_img(applied_vid_controls_frame)            # show frame in webpage? keen ideetjes hoe dat moet            # ik denk dat we elk frame moeten wegschrijven, elke x minuten (5?)            # dan die gewoon uitlezen met js            # show_frame_in_webpage(frame)    elif play_left:        if ret_left:            final = frame_left        else:            stop_video_stream()    elif play_right:        if ret_right:            final = frame_right        else:            stop_video_stream()    # show frame in opencv    show_frame_opencv(final, audio_player)    # cv2.waitKey(0)    # delay for fps only needed when showing in opencv window    if wait_for_key_per_frame:        # any key        cv2.waitKey(0)    else:        time.sleep(1 / fps)    # Press Q on keyboard to  exit    # if cv2.waitKey(25) & 0xFF == ord('q'):    #     break